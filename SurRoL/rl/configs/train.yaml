defaults:
  - agent: sac #changed from ddpgc 
  - _self_

# File path
cwd: ${hydra:runtime.output_dir}

# Training params
# Training params
n_train_steps: 100_000_001
n_eval: 10000
n_save: 5000
n_log: 100000
num_demo: 100
n_seed_steps: ${agent.n_seed_steps}

replay_buffer_capacity: 100_000
batch_size: 128
device: cuda:0
seed: 1
task: GauzeRetrieveRL-v0
postfix: null
dont_save: False
n_eval_episodes: 20
# This is key for HER to work well with sparse rewards
#for HPC demo path is:
demo_path: /l/users/khalfan.hableel/xarel/success_demo/data_GauzeRetrieveRL-v0_random_100.npz
use_wb: False
project_name: surrol_gauzeretriever_sac
entity_name: steph

# MPI
mpi: {rank: null, is_chef: null, num_workers: null}

# Working space
hydra:
  run:
    dir: ./exp_local/${task}/${agent.name}/d${num_demo}/s${seed}
  sweep:
    dir: ./exp_local/${task}/${agent.name}/d${num_demo}
    subdir: ${seed}
  sweeper:
    params:
      seed: 1,2,3,4,5
